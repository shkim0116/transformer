# transformer
- [Attention Is All You Need](https://arxiv.org/abs/1706.03762) 구현

### 한-영 번역 실험
- [한국어-영어 번역 말뭉치 데이터셋](https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=126) 사용
  

### 참고 사이트
- http://nlp.seas.harvard.edu/annotated-transformer/
- https://cpm0722.github.io/pytorch-implementation/transformer
